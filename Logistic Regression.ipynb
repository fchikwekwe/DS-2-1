{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Stats technique\n",
    "\n",
    "StatQuest Video: https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "#### - R squared can help to determine correlation and we can also use p values to determine confidence \n",
    "#### - Normal regression can use a single feature to predict a target value \n",
    "#### - Multiple regression uses multiple features to predict a single target value \n",
    "\n",
    "#### - Logistical regression predicts things that are true or false instead of continuous (e.g. obese vs not obese instead of weight and size)\n",
    "#### - Logistical regression is usually used for classification; we can also use use continuous data and discrete data as well an involving multiple features\n",
    "#### - We can use Wald's Test to determine if features are helpful for determining our target (if its effect is significantly different than zero) \n",
    "\n",
    "##### Question: How is statistical significance determined with regards to determining the helpfulness of features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "5              5      116             74              0        0  25.6   \n",
       "6              3       78             50             32       88  31.0   \n",
       "7             10      115              0              0        0  35.3   \n",
       "8              2      197             70             45      543  30.5   \n",
       "9              8      125             96              0        0   0.0   \n",
       "10             4      110             92              0        0  37.6   \n",
       "11            10      168             74              0        0  38.0   \n",
       "12            10      139             80              0        0  27.1   \n",
       "13             1      189             60             23      846  30.1   \n",
       "14             5      166             72             19      175  25.8   \n",
       "15             7      100              0              0        0  30.0   \n",
       "16             0      118             84             47      230  45.8   \n",
       "17             7      107             74              0        0  29.6   \n",
       "18             1      103             30             38       83  43.3   \n",
       "19             1      115             70             30       96  34.6   \n",
       "20             3      126             88             41      235  39.3   \n",
       "21             8       99             84              0        0  35.4   \n",
       "22             7      196             90              0        0  39.8   \n",
       "23             9      119             80             35        0  29.0   \n",
       "24            11      143             94             33      146  36.6   \n",
       "25            10      125             70             26      115  31.1   \n",
       "26             7      147             76              0        0  39.4   \n",
       "27             1       97             66             15      140  23.2   \n",
       "28            13      145             82             19      110  22.2   \n",
       "29             5      117             92              0        0  34.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "738            2       99             60             17      160  36.6   \n",
       "739            1      102             74              0        0  39.5   \n",
       "740           11      120             80             37      150  42.3   \n",
       "741            3      102             44             20       94  30.8   \n",
       "742            1      109             58             18      116  28.5   \n",
       "743            9      140             94              0        0  32.7   \n",
       "744           13      153             88             37      140  40.6   \n",
       "745           12      100             84             33      105  30.0   \n",
       "746            1      147             94             41        0  49.3   \n",
       "747            1       81             74             41       57  46.3   \n",
       "748            3      187             70             22      200  36.4   \n",
       "749            6      162             62              0        0  24.3   \n",
       "750            4      136             70              0        0  31.2   \n",
       "751            1      121             78             39       74  39.0   \n",
       "752            3      108             62             24        0  26.0   \n",
       "753            0      181             88             44      510  43.3   \n",
       "754            8      154             78             32        0  32.4   \n",
       "755            1      128             88             39      110  36.5   \n",
       "756            7      137             90             41        0  32.0   \n",
       "757            0      123             72              0        0  36.3   \n",
       "758            1      106             76              0        0  37.5   \n",
       "759            6      190             92              0        0  35.5   \n",
       "760            2       88             58             26       16  28.4   \n",
       "761            9      170             74             31        0  44.0   \n",
       "762            9       89             62              0        0  22.5   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "5                       0.201   30        0  \n",
       "6                       0.248   26        1  \n",
       "7                       0.134   29        0  \n",
       "8                       0.158   53        1  \n",
       "9                       0.232   54        1  \n",
       "10                      0.191   30        0  \n",
       "11                      0.537   34        1  \n",
       "12                      1.441   57        0  \n",
       "13                      0.398   59        1  \n",
       "14                      0.587   51        1  \n",
       "15                      0.484   32        1  \n",
       "16                      0.551   31        1  \n",
       "17                      0.254   31        1  \n",
       "18                      0.183   33        0  \n",
       "19                      0.529   32        1  \n",
       "20                      0.704   27        0  \n",
       "21                      0.388   50        0  \n",
       "22                      0.451   41        1  \n",
       "23                      0.263   29        1  \n",
       "24                      0.254   51        1  \n",
       "25                      0.205   41        1  \n",
       "26                      0.257   43        1  \n",
       "27                      0.487   22        0  \n",
       "28                      0.245   57        0  \n",
       "29                      0.337   38        0  \n",
       "..                        ...  ...      ...  \n",
       "738                     0.453   21        0  \n",
       "739                     0.293   42        1  \n",
       "740                     0.785   48        1  \n",
       "741                     0.400   26        0  \n",
       "742                     0.219   22        0  \n",
       "743                     0.734   45        1  \n",
       "744                     1.174   39        0  \n",
       "745                     0.488   46        0  \n",
       "746                     0.358   27        1  \n",
       "747                     1.096   32        0  \n",
       "748                     0.408   36        1  \n",
       "749                     0.178   50        1  \n",
       "750                     1.182   22        1  \n",
       "751                     0.261   28        0  \n",
       "752                     0.223   25        0  \n",
       "753                     0.222   26        1  \n",
       "754                     0.443   45        1  \n",
       "755                     1.057   37        1  \n",
       "756                     0.391   39        0  \n",
       "757                     0.258   52        1  \n",
       "758                     0.197   26        0  \n",
       "759                     0.278   66        1  \n",
       "760                     0.766   22        0  \n",
       "761                     0.403   43        1  \n",
       "762                     0.142   33        0  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima = pd.read_csv('diabetes.csv') \n",
    "pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age'] # these are the features that we will use for Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pima[feature_cols]\n",
    "y = pima['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.count() / pima['Pregnancies'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct zeros 118, wrong zeros 47, correct ones 15, wrong ones 12\n"
     ]
    }
   ],
   "source": [
    "correct_zero = 0\n",
    "wrong_zero = 0\n",
    "correct_one = 0\n",
    "wrong_one = 0 \n",
    "\n",
    "results = {}\n",
    "for index, value in enumerate(y_pred): \n",
    "    if value == 0:\n",
    "        if y_pred[index] == y_test.values.T[index]:\n",
    "            correct_zero += 1\n",
    "        else:\n",
    "            wrong_zero += 1\n",
    "    if value == 1:\n",
    "        if y_pred[index] == y_test.values.T[index]: \n",
    "            correct_one += 1\n",
    "        else: \n",
    "            wrong_one += 1\n",
    "\n",
    "        \n",
    "print(\"correct zeros {}, wrong zeros {}, correct ones {}, wrong ones {}\".format(correct_zero, wrong_zero, correct_one, wrong_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(118 + 15) / (47 + 118 + 15 + 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15 / (12 + 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63247571, 0.36752429],\n",
       "       [0.71643656, 0.28356344],\n",
       "       [0.71104114, 0.28895886],\n",
       "       [0.5858938 , 0.4141062 ],\n",
       "       [0.84103973, 0.15896027],\n",
       "       [0.82934844, 0.17065156],\n",
       "       [0.50110974, 0.49889026],\n",
       "       [0.48658459, 0.51341541],\n",
       "       [0.72321388, 0.27678612],\n",
       "       [0.32810562, 0.67189438],\n",
       "       [0.64244443, 0.35755557],\n",
       "       [0.25912035, 0.74087965],\n",
       "       [0.63949765, 0.36050235],\n",
       "       [0.76987637, 0.23012363],\n",
       "       [0.57345769, 0.42654231],\n",
       "       [0.80896485, 0.19103515],\n",
       "       [0.54236399, 0.45763601],\n",
       "       [0.8809859 , 0.1190141 ],\n",
       "       [0.56071047, 0.43928953],\n",
       "       [0.63038849, 0.36961151],\n",
       "       [0.55812011, 0.44187989],\n",
       "       [0.62388338, 0.37611662],\n",
       "       [0.80183978, 0.19816022],\n",
       "       [0.58322696, 0.41677304],\n",
       "       [0.84451719, 0.15548281],\n",
       "       [0.7468329 , 0.2531671 ],\n",
       "       [0.90256923, 0.09743077],\n",
       "       [0.30366288, 0.69633712],\n",
       "       [0.84641691, 0.15358309],\n",
       "       [0.7802164 , 0.2197836 ],\n",
       "       [0.56905168, 0.43094832],\n",
       "       [0.65783942, 0.34216058],\n",
       "       [0.77603886, 0.22396114],\n",
       "       [0.61926457, 0.38073543],\n",
       "       [0.86657866, 0.13342134],\n",
       "       [0.61209784, 0.38790216],\n",
       "       [0.52950297, 0.47049703],\n",
       "       [0.83795257, 0.16204743],\n",
       "       [0.70451824, 0.29548176],\n",
       "       [0.69081839, 0.30918161],\n",
       "       [0.72700295, 0.27299705],\n",
       "       [0.61183417, 0.38816583],\n",
       "       [0.72646557, 0.27353443],\n",
       "       [0.71118959, 0.28881041],\n",
       "       [0.36528086, 0.63471914],\n",
       "       [0.97634749, 0.02365251],\n",
       "       [0.84179352, 0.15820648],\n",
       "       [0.76981625, 0.23018375],\n",
       "       [0.6515407 , 0.3484593 ],\n",
       "       [0.72419959, 0.27580041],\n",
       "       [0.66735896, 0.33264104],\n",
       "       [0.75119404, 0.24880596],\n",
       "       [0.25510488, 0.74489512],\n",
       "       [0.60998536, 0.39001464],\n",
       "       [0.58374455, 0.41625545],\n",
       "       [0.86424313, 0.13575687],\n",
       "       [0.81104624, 0.18895376],\n",
       "       [0.35222318, 0.64777682],\n",
       "       [0.81077869, 0.18922131],\n",
       "       [0.94314096, 0.05685904],\n",
       "       [0.36008453, 0.63991547],\n",
       "       [0.53363618, 0.46636382],\n",
       "       [0.8749028 , 0.1250972 ],\n",
       "       [0.73042398, 0.26957602],\n",
       "       [0.75080896, 0.24919104],\n",
       "       [0.69429604, 0.30570396],\n",
       "       [0.53623776, 0.46376224],\n",
       "       [0.79036905, 0.20963095],\n",
       "       [0.57152171, 0.42847829],\n",
       "       [0.59237736, 0.40762264],\n",
       "       [0.79830904, 0.20169096],\n",
       "       [0.72972934, 0.27027066],\n",
       "       [0.73744144, 0.26255856],\n",
       "       [0.42761737, 0.57238263],\n",
       "       [0.54532959, 0.45467041],\n",
       "       [0.72283848, 0.27716152],\n",
       "       [0.41998719, 0.58001281],\n",
       "       [0.58400512, 0.41599488],\n",
       "       [0.72723899, 0.27276101],\n",
       "       [0.65900777, 0.34099223],\n",
       "       [0.45373422, 0.54626578],\n",
       "       [0.62069277, 0.37930723],\n",
       "       [0.7007795 , 0.2992205 ],\n",
       "       [0.89940831, 0.10059169],\n",
       "       [0.67127398, 0.32872602],\n",
       "       [0.54898637, 0.45101363],\n",
       "       [0.83963021, 0.16036979],\n",
       "       [0.5103025 , 0.4896975 ],\n",
       "       [0.36769492, 0.63230508],\n",
       "       [0.59261596, 0.40738404],\n",
       "       [0.80205603, 0.19794397],\n",
       "       [0.80301979, 0.19698021],\n",
       "       [0.75536792, 0.24463208],\n",
       "       [0.88852815, 0.11147185],\n",
       "       [0.5841403 , 0.4158597 ],\n",
       "       [0.78438144, 0.21561856],\n",
       "       [0.45875471, 0.54124529],\n",
       "       [0.51196398, 0.48803602],\n",
       "       [0.35347233, 0.64652767],\n",
       "       [0.66059342, 0.33940658],\n",
       "       [0.45736573, 0.54263427],\n",
       "       [0.83786176, 0.16213824],\n",
       "       [0.6221259 , 0.3778741 ],\n",
       "       [0.88688713, 0.11311287],\n",
       "       [0.65218013, 0.34781987],\n",
       "       [0.65957216, 0.34042784],\n",
       "       [0.8209015 , 0.1790985 ],\n",
       "       [0.78675188, 0.21324812],\n",
       "       [0.85289054, 0.14710946],\n",
       "       [0.76985898, 0.23014102],\n",
       "       [0.81595408, 0.18404592],\n",
       "       [0.47775351, 0.52224649],\n",
       "       [0.52900634, 0.47099366],\n",
       "       [0.71115752, 0.28884248],\n",
       "       [0.50674921, 0.49325079],\n",
       "       [0.58255527, 0.41744473],\n",
       "       [0.77084992, 0.22915008],\n",
       "       [0.72977089, 0.27022911],\n",
       "       [0.80756076, 0.19243924],\n",
       "       [0.2501287 , 0.7498713 ],\n",
       "       [0.53499907, 0.46500093],\n",
       "       [0.3354546 , 0.6645454 ],\n",
       "       [0.57901401, 0.42098599],\n",
       "       [0.46435966, 0.53564034],\n",
       "       [0.83965298, 0.16034702],\n",
       "       [0.8564314 , 0.1435686 ],\n",
       "       [0.61857574, 0.38142426],\n",
       "       [0.66172686, 0.33827314],\n",
       "       [0.6369935 , 0.3630065 ],\n",
       "       [0.87157469, 0.12842531],\n",
       "       [0.71666307, 0.28333693],\n",
       "       [0.95994442, 0.04005558],\n",
       "       [0.81518861, 0.18481139],\n",
       "       [0.33283053, 0.66716947],\n",
       "       [0.53647126, 0.46352874],\n",
       "       [0.51284318, 0.48715682],\n",
       "       [0.80089206, 0.19910794],\n",
       "       [0.54138349, 0.45861651],\n",
       "       [0.76783279, 0.23216721],\n",
       "       [0.81630733, 0.18369267],\n",
       "       [0.73608006, 0.26391994],\n",
       "       [0.62507031, 0.37492969],\n",
       "       [0.87083494, 0.12916506],\n",
       "       [0.58586087, 0.41413913],\n",
       "       [0.57539142, 0.42460858],\n",
       "       [0.86167809, 0.13832191],\n",
       "       [0.79218306, 0.20781694],\n",
       "       [0.70522301, 0.29477699],\n",
       "       [0.84174901, 0.15825099],\n",
       "       [0.63983766, 0.36016234],\n",
       "       [0.76258551, 0.23741449],\n",
       "       [0.56649311, 0.43350689],\n",
       "       [0.79380119, 0.20619881],\n",
       "       [0.76837662, 0.23162338],\n",
       "       [0.38888459, 0.61111541],\n",
       "       [0.80268991, 0.19731009],\n",
       "       [0.19928502, 0.80071498],\n",
       "       [0.82191509, 0.17808491],\n",
       "       [0.63511265, 0.36488735],\n",
       "       [0.21381357, 0.78618643],\n",
       "       [0.55919386, 0.44080614],\n",
       "       [0.63440346, 0.36559654],\n",
       "       [0.88239862, 0.11760138],\n",
       "       [0.77156675, 0.22843325],\n",
       "       [0.52134931, 0.47865069],\n",
       "       [0.78679475, 0.21320525],\n",
       "       [0.48501479, 0.51498521],\n",
       "       [0.83877506, 0.16122494],\n",
       "       [0.76259881, 0.23740119],\n",
       "       [0.70625609, 0.29374391],\n",
       "       [0.83329952, 0.16670048],\n",
       "       [0.51283474, 0.48716526],\n",
       "       [0.70030106, 0.29969894],\n",
       "       [0.55348957, 0.44651043],\n",
       "       [0.49830098, 0.50169902],\n",
       "       [0.70753494, 0.29246506],\n",
       "       [0.38263772, 0.61736228],\n",
       "       [0.58406005, 0.41593995],\n",
       "       [0.74179055, 0.25820945],\n",
       "       [0.8258032 , 0.1741968 ],\n",
       "       [0.66480459, 0.33519541],\n",
       "       [0.30393175, 0.69606825],\n",
       "       [0.67545632, 0.32454368],\n",
       "       [0.64269574, 0.35730426],\n",
       "       [0.7663053 , 0.2336947 ],\n",
       "       [0.76261476, 0.23738524],\n",
       "       [0.61590682, 0.38409318],\n",
       "       [0.75308588, 0.24691412],\n",
       "       [0.72045448, 0.27954552],\n",
       "       [0.81498826, 0.18501174],\n",
       "       [0.7377638 , 0.2622362 ],\n",
       "       [0.72143074, 0.27856926]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# probability \n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.375, 0.75, 0.5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_metrics(TP, FP, TN, FN):\n",
    "    \"\"\" \n",
    "    Params: TP = True positive, FP = False positive, TN = True negative, FN = False negative\n",
    "    Returns: Array with accuracy, precision, recall, F1_score\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    metrics.append(accuracy)\n",
    "    \n",
    "    precision = (TP) / (TP + FP)\n",
    "    metrics.append(precision)\n",
    "    \n",
    "    recall = (TP) / (FN + TP)\n",
    "    metrics.append(recall)\n",
    "    \n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    metrics.append(F1_score)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "#calculate evaluation metrics of RoboCop data\n",
    "evaluation_metrics(3, 5, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6927083333333334,\n",
       " 0.5555555555555556,\n",
       " 0.24193548387096775,\n",
       " 0.3370786516853933]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of diabetes confusion matrix\n",
    "confusion = np.array ([[118., 12.], [47., 15.]])\n",
    "\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "TP = confusion[1, 1]\n",
    "\n",
    "#calculate the evaluation metrics of our diabetes data\n",
    "evaluation_metrics(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADSBJREFUeJzt3X+MHPdZx/H3U7uh/GhJGl8qKw5citwSg0ojjihSJQRJi0wMiREGOaLIkQwWJZSiVqKG8ge/JByQmiIRCZmmiougSeoi2SQFlLq2qlZNyqVxEhwrdRIOsBLF1zahFETB7cMfO24W5+yd3dudXT99v6TTzcx+1/Px3N3n5mZ2ZiMzkSRd+F4x7QCSpPGw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCAtdkoqw0CWpCAtdkopY2+XK1q1bl/Pz812uUpIueA8//PAXM3Nu0LhOC31+fp7FxcUuVylJF7yI+Jc24zzkIklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFdHqlqLozv/v+aUdY0dKeLdOOIJXlHrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IRFrokFWGhS1IR3pxrlWb1JliSvvW4hy5JRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRVjoklSEhS5JRbQu9IhYExGPRMR9zfyVEfFQRJyIiHsi4qLJxZQkDTLMHvq7gON987cBt2fmRuAFYOc4g0mShtOq0CNiA7AF+GAzH8B1wP5myD5g6yQCSpLaabuH/gHgN4FvNPOXAi9m5ulm/iRw+ZizSZKGMLDQI+KngFOZ+XD/4hWG5jmevysiFiNicXl5ecSYkqRB2uyhvwW4MSKWgLvpHWr5AHBxRJy5/e4G4NmVnpyZezNzITMX5ubmxhBZkrSSgYWemb+VmRsycx7YDnwyM38BOAxsa4btAA5MLKUkaaDVvA79vcC7I+IpesfU7xxPJEnSKIZ6x6LMPAIcaaafAa4ZfyRJ0ii8UlSSirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SihjqbotSVfO77592hBUt7dky7Qi6gLiHLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklF+I5F6tSsvjOQVIF76JJUhIUuSUVY6JJUhIUuSUUMLPSIeFVEfC4iHo2IYxHxe83yKyPioYg4ERH3RMRFk48rSTqXNnvoXwOuy8wfAt4MbI6Ia4HbgNszcyPwArBzcjElSYMMLPTs+Woz+8rmI4HrgP3N8n3A1okklCS10uoYekSsiYijwCngAeBp4MXMPN0MOQlcPpmIkqQ2WhV6Zn49M98MbACuAa5aadhKz42IXRGxGBGLy8vLoyeVJJ3XUK9yycwXgSPAtcDFEXHmStMNwLPneM7ezFzIzIW5ubnVZJUknUebV7nMRcTFzfS3A28FjgOHgW3NsB3AgUmFlCQN1uZeLuuBfRGxht4vgHsz876IeAK4OyL+EHgEuHOCOSVJAwws9Mx8DLh6heXP0DueLkmaAV4pKklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVMTAQo+IKyLicEQcj4hjEfGuZvlrI+KBiDjRfL5k8nElSefSZg/9NPCezLwKuBa4NSI2AbuBQ5m5ETjUzEuSpmRgoWfmc5n5+Wb6P4DjwOXATcC+Ztg+YOukQkqSBhvqGHpEzANXAw8Br8vM56BX+sBl4w4nSWqvdaFHxHcBHwN+IzO/MsTzdkXEYkQsLi8vj5JRktRCq0KPiFfSK/O/ysy/aRY/HxHrm8fXA6dWem5m7s3MhcxcmJubG0dmSdIK2rzKJYA7geOZ+f6+hw4CO5rpHcCB8ceTJLW1tsWYtwC/CDweEUebZb8N7AHujYidwL8CPzeZiJKkNgYWemZ+GohzPHz9eONIkkbllaKSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVISFLklFWOiSVMTaaQeQdOGZ333/tCOsaGnPlmlHmCr30CWpCAtdkoqw0CWpCAtdkooYWOgR8aGIOBUR/9S37LUR8UBEnGg+XzLZmJKkQdrsod8FbD5r2W7gUGZuBA4185KkKRpY6Jn5KeDLZy2+CdjXTO8Dto45lyRpSKMeQ39dZj4H0Hy+bHyRJEmjmPhJ0YjYFRGLEbG4vLw86dVJ0resUQv9+YhYD9B8PnWugZm5NzMXMnNhbm5uxNVJkgYZtdAPAjua6R3AgfHEkSSNqs3LFj8CfBZ4Y0ScjIidwB7gbRFxAnhbMy9JmqKBN+fKzJvP8dD1Y85yXrN6MyBpkvy+1zC8UlSSirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12SirDQJakIC12Sihj4jkWSdKGY1Xd4WtqzpZP1uIcuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUhIUuSUVY6JJUxKoKPSI2R8STEfFUROweVyhJ0vBGLvSIWAPcAfwksAm4OSI2jSuYJGk4q9lDvwZ4KjOfycz/Ae4GbhpPLEnSsFZT6JcD/9Y3f7JZJkmagrWreG6ssCxfNihiF7Crmf1qRDy5wvPWAV9cRZZJMttozDa6Wc5nthHEbavO9r1tBq2m0E8CV/TNbwCePXtQZu4F9p7vH4qIxcxcWEWWiTHbaMw2ulnOZ7bRdJVtNYdc/hHYGBFXRsRFwHbg4HhiSZKGNfIeemaejohfA/4BWAN8KDOPjS2ZJGkoqznkQmZ+HPj4GHKc95DMlJltNGYb3SznM9toOskWmS87jylJugB56b8kFdFpoQ+6VUBEfFtE3NM8/lBEzM9Qth+NiM9HxOmI2NZVrpbZ3h0RT0TEYxFxKCJavcSpo2y/EhGPR8TRiPh0l1cTt701RURsi4iMiM5eIdFiu90SEcvNdjsaEb80K9maMT/ffM8di4i/7ipbm3wRcXvfdvtCRLw4Q9m+JyIOR8Qjzc/rDWMNkJmdfNA7cfo08HrgIuBRYNNZY34V+PNmejtwzwxlmwfeBHwY2DZj2+3Hge9opt8xY9vtNX3TNwJ/PyvZmnGvBj4FPAgszEo24Bbgz7r6Phsy20bgEeCSZv6yWcp31vh30nvBxkxko3cs/R3N9CZgaZwZutxDb3OrgJuAfc30fuD6iFjpAqbOs2XmUmY+BnyjgzzDZjucmf/VzD5I75qAWcn2lb7Z72SFi8+mla3xB8AfA//dUa5hsk1Dm2y/DNyRmS8AZOapGcvX72bgI50ka5ctgdc009/NCtfurEaXhd7mVgHfHJOZp4F/By6dkWzTMmy2ncDfTTTRS1pli4hbI+JpesX567OSLSKuBq7IzPs6ynRG26/pzzZ/lu+PiCtWeHwS2mR7A/CGiPhMRDwYEZs7ygZD/Dw0hx6vBD7ZQS5ol+13gbdHxEl6rxB85zgDdFnobW4V0Op2AhMwrfW20TpbRLwdWAD+ZKKJ+la5wrKXZcvMOzLz+4D3Ar8z8VQ9580WEa8Abgfe01Gefm22298C85n5JuATvPSX66S1ybaW3mGXH6O3B/zBiLh4wrnOGOZndTuwPzO/PsE8/dpkuxm4KzM3ADcAf9l8L45Fl4Xe5lYB3xwTEWvp/Uny5RnJNi2tskXEW4H3ATdm5tdmKVufu4GtE030kkHZXg38IHAkIpaAa4GDHZ0YHbjdMvNLfV/HvwB+uINcrbI1Yw5k5v9m5j8DT9Ir+FnJd8Z2ujvcAu2y7QTuBcjMzwKvoncPmvHo8GTGWuAZen8CnTlh8ANnjbmV/39S9N5ZydY39i66PSnaZrtdTe9kzMaucg2RbWPf9E8Di7OS7azxR+jupGib7ba+b/pngAdnKNtmYF8zvY7eYYZLZyVfM+6NwBLNtTazko3e4dBbmumr6BX+2DJ28h/t+8/cAHyhKZ/3Nct+n95eJfR+W30UeAr4HPD6Gcr2I/R+A/8n8CXg2Axl+wTwPHC0+Tg4Q9n+FDjW5Dp8vlLtOttZYzsr9Jbb7Y+a7fZos92+f4ayBfB+4AngcWB7V9nafl3pHave02WulttuE/CZ5ut6FPiJca7fK0UlqQivFJWkIix0SSrCQpekIix0SSrCQpekIix0SSrCQpekIix0SSri/wC1l0tR+Gh/kQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_prob[:, 1], bins=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3576388888888889"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = y_train.value_counts()[1] / len(y_train)\n",
    "up_to_one = y_pred_prob[:, 1]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_greater(threshold, up_to_one):\n",
    "    above_threshold = []\n",
    "    below_threshold = []\n",
    "    \n",
    "    for value in up_to_one:\n",
    "        if value > threshold: \n",
    "            above_threshold.append(1)\n",
    "        else: \n",
    "            below_threshold.append(0)\n",
    "            \n",
    "    results = []\n",
    "    \n",
    "    results += above_threshold\n",
    "    results += below_threshold\n",
    "    \n",
    "    print(len(above_threshold))\n",
    "    print(len(below_threshold))\n",
    "    \n",
    "    return results\n",
    "\n",
    "new_y_pred = predict_greater(threshold, up_to_one)\n",
    "len(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75, 55],\n",
       "       [36, 26]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_confusion = metrics.confusion_matrix(y_test, new_y_pred)\n",
    "optimal_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
